{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759719fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy.signal import find_peaks, periodogram, welch\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./dataset/order_imported.csv')\n",
    "\n",
    "assumptions = \"\"\"Assumptions:\n",
    "\n",
    "1. Order import -> Fraud Check -> Authorized Order -> Pick Ticket\n",
    "2. No missing values exist\n",
    "3. Cycles happening daily / weekly / business\n",
    "4. Trends happen due to holidays on Black Friday and Christmas\n",
    "5. 30 minute windows\n",
    "6. All datasets are synced to same timezones and timestamps\n",
    "\"\"\"\n",
    "\n",
    "print(assumptions)\n",
    "\n",
    "# Convert 'ds' to datetime and set 30-minute frequency\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df.set_index('ds').asfreq('30min').reset_index()\n",
    "\n",
    "# Linearly interpolate missing rows\n",
    "df = df.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2fa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preliminary information\n",
    "\n",
    "def print_df_info(df : pd.DataFrame, name : str) -> None:\n",
    "    print(f\"Preliminary information for {name}\")\n",
    "    print(f\"Size: {len(df)}\\n\")\n",
    "    print(f\"'y' min and max: {df['y'].min()}, {df['y'].max()}\\n\")\n",
    "   \n",
    "    print(\"column dtypes:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  {col}: {df[col].dtype}\")\n",
    "\n",
    "\n",
    "# Reverse the dataframe to have chronological order (oldest first)\n",
    "df = df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "SIZE = len(df)\n",
    "SPLIT = 1680\n",
    "print_df_info(df, \"Imported Orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Summaries\n",
    "\n",
    "def print_y_summaries(df : pd.DataFrame, name : str) -> None:\n",
    "    \"\"\"\n",
    "    print global y-statistics\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'y' column\n",
    "    \"\"\"\n",
    "    print(f\"Global Stats: 'y' ({name}):\\n\")\n",
    "    print(f\"Mean: {df['y'].mean():.2f}\")\n",
    "    print(f\"Median: {df['y'].median():.2f}\")\n",
    "    print(f\"Std: {df['y'].std():.2f}\")\n",
    "    print(f\"IQR: {df['y'].quantile(0.75) - df['y'].quantile(0.25):.2f}\")\n",
    "    print(f\"Min: {df['y'].min()}\")\n",
    "    print(f\"Max: {df['y'].max()}\")\n",
    "    print(f\"Skewness: {df['y'].skew():.2f}\")\n",
    "    print(f\"Kurtosis: {df['y'].kurtosis():.2f}\")\n",
    "\n",
    "\n",
    "def plot_rolling_y(df: pd.DataFrame, name : str, n: int) -> None:\n",
    "    \"\"\"\n",
    "    Calculate and plot rolling mean, median, IQR, std for 'y' column\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'y' column\n",
    "    n: rolling window size\n",
    "    \"\"\"\n",
    "    # Calculate rolling statistics\n",
    "    rolling_mean = df['y'].rolling(window=n).mean()\n",
    "    rolling_median = df['y'].rolling(window=n).median()\n",
    "    rolling_std = df['y'].rolling(window=n).std()\n",
    "    rolling_iqr = df['y'].rolling(window=n).apply(lambda x: x.quantile(0.75) - x.quantile(0.25))\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(6, 5))\n",
    "    fig.suptitle(f\"Rolling Stats: {name}, 'y' (Window Size: {n})\", fontsize=16)\n",
    "    \n",
    "    # Plot rolling mean\n",
    "    axes[0].plot(df.index, rolling_mean, label=f'Rolling Mean (n={n})', color='blue')\n",
    "    axes[0].set_ylabel('Mean')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot rolling median\n",
    "    axes[1].plot(df.index, rolling_median, label=f'Rolling Median (n={n})', color='green')\n",
    "    axes[1].set_ylabel('Median')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot rolling std\n",
    "    axes[2].plot(df.index, rolling_std, label=f'Rolling Std (n={n})', color='red')\n",
    "    axes[2].set_ylabel('Std')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot rolling IQR\n",
    "    axes[3].plot(df.index, rolling_iqr, label=f'Rolling IQR (n={n})', color='orange')\n",
    "    axes[3].set_ylabel('IQR')\n",
    "    axes[3].set_xlabel('Time (30 mins)')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print_y_summaries(df, \"Imported Orders\")\n",
    "for n in (48, 168, 1460):\n",
    "    plot_rolling_y(df, \"Imported Orders\", n=n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Vizualizations\n",
    "def graph_y_time(df : pd.DataFrame, name : str):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df.index, df['y'], label=f'{name} (y)')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Imported Orders (y)')\n",
    "    plt.title('Imported Orders Over Time')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_y_analysis(df: pd.DataFrame, name: str):\n",
    "    \"\"\"\n",
    "    Comprehensive visualization suite for y-feature analysis\n",
    "    \"\"\"\n",
    "            \n",
    "    # Create a comprehensive subplot figure with all visualizations\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.5, wspace=0.3)\n",
    "    fig.suptitle(f'{name}: Comprehensive Y-Feature Analysis', fontsize=16)\n",
    "    \n",
    "    # Zoomed windows (random + recent)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    random_start = len(df) // 2 - 100\n",
    "    random_end = random_start + 200\n",
    "    ax1.plot(df.index[random_start:random_end], df['y'].iloc[random_start:random_end])\n",
    "    ax1.set_title('Random Window (Middle 200 points)')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.plot(df.index[-200:], df['y'].iloc[-200:], color='orange')\n",
    "    ax2.set_title('Recent Window (Last 200 points)')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rolling mean/std overlay\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    window = 48\n",
    "    rolling_mean = df['y'].rolling(window=window).mean()\n",
    "    rolling_std = df['y'].rolling(window=window).std()\n",
    "    \n",
    "    ax3.plot(df.index, df['y'], alpha=0.5, label='Raw Data', linewidth=0.8)\n",
    "    ax3.plot(df.index, rolling_mean, label=f'Rolling Mean (n={window})', color='red', linewidth=2)\n",
    "    ax3.fill_between(df.index, rolling_mean - rolling_std, rolling_mean + rolling_std, \n",
    "                     alpha=0.2, color='red', label='Â±1 Std Dev')\n",
    "    ax3.set_ylabel('y')\n",
    "    ax3.set_title('Rolling Mean/Std Overlay')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram + KDE\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    ax4.hist(df['y'], bins=30, density=True, alpha=0.7, edgecolor='black', label='Histogram')\n",
    "    df['y'].plot(kind='kde', ax=ax4, color='red', linewidth=2, label='KDE')\n",
    "    ax4.set_xlabel('y')\n",
    "    ax4.set_ylabel('Density')\n",
    "    ax4.set_title('Distribution (Histogram + KDE)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "    # Boxplot by time bucket (48/168/1460)\n",
    "    buckets = [48, 168, 1460]\n",
    "    for i, bucket_size in enumerate(buckets):\n",
    "        ax = fig.add_subplot(gs[3, i])\n",
    "        df_copy = df.copy()\n",
    "        df_copy['bucket'] = df_copy.index // bucket_size\n",
    "        df_copy.boxplot(column='y', by='bucket', ax=ax)\n",
    "        ax.set_title(f'Bucket Size: {bucket_size}')\n",
    "        ax.set_xlabel('Bucket')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.get_figure().suptitle('')  # Remove automatic title from boxplot\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        # 48 labels were messy\n",
    "        if bucket_size == 48:\n",
    "            labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "            new_labels = [label if i % 2 == 0 else '' for i, label in enumerate(labels)]\n",
    "            ax.set_xticklabels(new_labels)\n",
    "    plt.show()\n",
    "    \n",
    "graph_y_time(df[1000:3000], \"Imported Orders\")\n",
    "# plot_y_analysis(df, \"Imported Orders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59521f9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Create differenced and scaled y_detrended column\n",
    "df['y_detrended'] = df['y'].diff().fillna(0)\n",
    "\n",
    "def graph_y_detrended(df: pd.DataFrame, name: str, feature : str = 'y_detrended'):\n",
    "    \"\"\"\n",
    "    Plot the y_detrended column over time\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'y_detrended' column\n",
    "    name: Name for the plot title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df.index, df[feature], label=f'{name} {feature}', color='purple')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(f'{name}: Differenced and Scaled Y {feature} Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "graph_y_detrended(df, \"Imported Orders\")\n",
    "\n",
    "def plot_acf_pacf(ds, name: str, lag = 200, do_pacf = True):\n",
    "    \"\"\"\n",
    "    Plot ACF and PACF for a given column\n",
    "    \n",
    "    Parameters:\n",
    "    ds: dataseries\n",
    "    name: Name for the plot title\n",
    "    \"\"\"\n",
    "    # Plot ACF\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plot_acf(ds, lags=lag, ax=ax)\n",
    "    ax.set_title(f'Autocorrelation Function (ACF): {name}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if not do_pacf:\n",
    "        return\n",
    "\n",
    "    # Plot PACF\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plot_pacf(ds, lags=lag, ax=ax)\n",
    "    ax.set_title(f'Partial Autocorrelation Function (PACF): {name}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_periodogram_welch(df: pd.DataFrame, name: str, feature = 'y_detrended'):\n",
    "    \"\"\"\n",
    "    Plot periodogram and Welch's PSD for y_detrended column\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'y_detrended' column\n",
    "    name: Name for the plot title\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f'Frequency Domain Analysis: {name} {feature}', fontsize=16)\n",
    "    \n",
    "    # Periodogram\n",
    "    frequencies, psd = periodogram(df[feature])\n",
    "    mask = frequencies > 0\n",
    "    axes[0].semilogy(frequencies[mask], psd[mask])\n",
    "    axes[0].set_xlabel('Frequency')\n",
    "    axes[0].set_ylabel('Power Spectral Density')\n",
    "    axes[0].set_title('Periodogram')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Welch's PSD\n",
    "    frequencies_welch, psd_welch = welch(df[feature], fs=1, nperseg=256)\n",
    "    mask_welch = frequencies_welch > 0\n",
    "    axes[1].semilogy(frequencies_welch[mask_welch], psd_welch[mask_welch])\n",
    "    axes[1].set_xlabel('Frequency')\n",
    "    axes[1].set_ylabel('Power Spectral Density')\n",
    "    axes[1].set_title(\"Welch's PSD\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return frequencies_welch, psd_welch\n",
    "\n",
    "plot_acf_pacf(df['y_detrended'], \"Imported Orders\", 200)\n",
    "frequencies, psd = plot_periodogram_welch(df, \"Imported Orders\")\n",
    "print(len(df))\n",
    "\n",
    "peaks, _ = find_peaks(psd, height=np.median(psd)*1)\n",
    "\n",
    "peak_freqs = frequencies[peaks]\n",
    "peak_periods = 1 / peak_freqs\n",
    "print(\"Significant Periods (in time units):\", peak_periods)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# absolute outliers\n",
    "filter = HampelFilter(window_length=50, n_sigma = 5.0, return_bool=True)\n",
    "train_mask = filter.fit_transform(df['y_detrended'])\n",
    "\n",
    "df.loc[train_mask, 'y'], df.loc[train_mask, 'y_detrended'] = None, None\n",
    "df.loc[:, 'y'] = (df['y'].interpolate(method='linear', limit_direction='both'))\n",
    "df.loc[:, 'y_detrended'] = (df['y_detrended'].interpolate(method='linear', limit_direction='both'))\n",
    "\n",
    "\n",
    "# Apply log transformation to 'y' column in train_df\n",
    "df['y_log'] = np.log(df['y'])\n",
    "df['y_detrended'] = df['y_log'].diff().fillna(0)\n",
    "df['y_detrended_nolog'] = df['y'].diff().fillna(0)\n",
    "\n",
    "train_df = df[:SPLIT]\n",
    "test_df = df[SPLIT:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22924ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def graph_mstl(df: pd.DataFrame, name: str, seasonal_lengths: list, graph = True, feature = 'y_log'):\n",
    "    \"\"\"\n",
    "    Plot Multiple Seasonal-Trend decomposition using LOESS (MSTL)\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with 'y' column\n",
    "    name: Name for the plot title\n",
    "    seasonal_lengths: List of seasonal period lengths (e.g., [24, 168] for daily and weekly patterns)\n",
    "    \"\"\"\n",
    "    from statsmodels.tsa.seasonal import MSTL\n",
    "    \n",
    "    # Perform MSTL decomposition\n",
    "    mstl = MSTL(df[feature], periods=seasonal_lengths, stl_kwargs={'robust': False})\n",
    "    result = mstl.fit()\n",
    "\n",
    "    if not graph:\n",
    "        return result\n",
    "    \n",
    "    # Create subplots: original + trend + multiple seasonals + residual\n",
    "    n_plots = 3 + len(seasonal_lengths)  # original, trend, seasonals, residual\n",
    "    fig, axes = plt.subplots(n_plots, 1, figsize=(12, 3 * n_plots))\n",
    "    fig.suptitle(f'MSTL Decomposition: {name} (Periods: {seasonal_lengths})', fontsize=16)\n",
    "    \n",
    "    # Plot original series\n",
    "    axes[0].plot(df.index, df[feature], label='Original', color='black')\n",
    "    axes[0].set_ylabel('Original')\n",
    "    axes[0].legend(loc='upper left')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot trend\n",
    "    axes[1].plot(df.index, result.trend, label='Trend', color='blue')\n",
    "    axes[1].set_ylabel('Trend')\n",
    "    axes[1].legend(loc='upper left')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot each seasonal component\n",
    "    colors = ['green', 'orange', 'purple', 'red', 'brown', 'pink']\n",
    "    for i, period in enumerate(seasonal_lengths):\n",
    "        seasonal = result.seasonal\n",
    "        axes[2 + i].plot(df.index, seasonal, label=f'Seasonal (period={period})', color=colors[i % len(colors)])\n",
    "        axes[2 + i].set_ylabel(f'Seasonal_{period}')\n",
    "        axes[2 + i].legend(loc='upper left')\n",
    "        axes[2 + i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot residual\n",
    "    axes[-1].plot(df.index, result.resid, label='Residual', color='red', alpha=0.7)\n",
    "    axes[-1].set_ylabel('Residual')\n",
    "    axes[-1].set_xlabel('Time (30 mins)')\n",
    "    axes[-1].legend(loc='upper left')\n",
    "    axes[-1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# possible seasonal lengths: 24, 772, 1460, 4383 \n",
    "\n",
    "# Generate all possible non-empty subsets\n",
    "train_resid = graph_mstl(train_df, \"Imported Orders\", [48, 336], False).resid.to_frame().rename(columns={'resid': 'y_detrended'})\n",
    "test_resid = graph_mstl(test_df, \"Imported Orders\", [48, 336], False).resid.to_frame().rename(columns={'resid': 'y_detrended'})\n",
    "plot_acf_pacf(train_resid, \"Imported Orders\", 200, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data looks clean - now save\n",
    "# note - df clean removed outliers and entries < 400 because they were during abnormal holiday period\n",
    "train_df.loc[:, 'resid'] = train_resid['y_detrended']\n",
    "test_df.loc[:, 'resid'] = test_resid['y_detrended']\n",
    "\n",
    "# Create holiday mask for Black Friday weekend (4th Thursday of Nov 5:30 AM to following Monday 11:30 PM)\n",
    "train_df['ds_datetime'] = pd.to_datetime(train_df['ds'])\n",
    "test_df['ds_datetime'] = pd.to_datetime(test_df['ds'])\n",
    "\n",
    "# Initialize holiday column\n",
    "train_df['holiday'] = 0\n",
    "test_df['holiday'] = 0\n",
    "\n",
    "# Find Black Friday periods for each year in the dataset\n",
    "for year in train_df['ds_datetime'].dt.year.unique():\n",
    "    # Find 4th Thursday of November\n",
    "    nov_first = pd.Timestamp(f'{year}-11-01')\n",
    "    # Find first Thursday\n",
    "    days_until_thursday = (3 - nov_first.dayofweek) % 7\n",
    "    first_thursday = nov_first + pd.Timedelta(days=days_until_thursday)\n",
    "    # 4th Thursday is 3 weeks later\n",
    "    fourth_thursday = first_thursday + pd.Timedelta(weeks=3)\n",
    "    \n",
    "    # Black Friday weekend: Thursday 5:30 AM to Monday 11:30 PM\n",
    "    start_time = fourth_thursday + pd.Timedelta(hours=5, minutes=30)\n",
    "    end_time = fourth_thursday + pd.Timedelta(days=4, hours=23, minutes=30)\n",
    "    \n",
    "    # Mark holiday periods\n",
    "    train_df.loc[(train_df['ds_datetime'] >= start_time) & (train_df['ds_datetime'] <= end_time), 'holiday'] = 1\n",
    "\n",
    "for year in test_df['ds_datetime'].dt.year.unique():\n",
    "    nov_first = pd.Timestamp(f'{year}-11-01')\n",
    "    days_until_thursday = (3 - nov_first.dayofweek) % 7\n",
    "    first_thursday = nov_first + pd.Timedelta(days=days_until_thursday)\n",
    "    fourth_thursday = first_thursday + pd.Timedelta(weeks=3)\n",
    "    \n",
    "    start_time = fourth_thursday + pd.Timedelta(hours=5, minutes=30)\n",
    "    end_time = fourth_thursday + pd.Timedelta(days=4, hours=23, minutes=30)\n",
    "    \n",
    "    test_df.loc[(test_df['ds_datetime'] >= start_time) & (test_df['ds_datetime'] <= end_time), 'holiday'] = 1\n",
    "\n",
    "# Drop temporary datetime column\n",
    "train_df = train_df.drop('ds_datetime', axis=1)\n",
    "test_df = test_df.drop('ds_datetime', axis=1)\n",
    "\n",
    "if 'unique_id' in train_df.columns:\n",
    "    train_df = train_df.drop('unique_id', axis=1)\n",
    "    test_df = test_df.drop('unique_id', axis=1)\n",
    "\n",
    "\n",
    "test_df.insert(0, 'unique_id', 'OrderImport')\n",
    "train_df.insert(0, 'unique_id', 'OrderImport')\n",
    "\n",
    "\n",
    "train_df.to_csv('./dataset/cleaned/auth_order_train.csv', index=False)\n",
    "test_df.to_csv('./dataset/cleaned/auth_order_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
